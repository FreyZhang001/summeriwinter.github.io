<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Frey's blog</title><link rel="stylesheet" type="text/css" href="/css/style.css"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.png"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script></head><script src="https://www.googletagmanager.com/gtag/js?id=UA-111205240-3" async></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-111205240-3');
</script><script src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><script>(adsbygoogle = window.adsbygoogle || []).push({
  google_ad_client: "ca-pub-3597458182538053",
  enable_page_level_ads: true
});</script><script custom-element="amp-ad" src="https://cdn.ampproject.org/v0/amp-ad-0.1.js" async></script><link rel="stylesheet" type="text/css" href="/plugins/prettify/doxy.css"><script type="text/javascript" src="/js/ready.js" async></script><body><div class="mobile-head" id="mobile-head"><div class="navbar-icon"><span></span><span></span><span></span></div><div class="navbar-title"><a href="/">Frey's blog</a></div><div class="navbar-search"><!--= show a circle here--></div></div><div class="h-wrapper" id="menu"><nav class="h-head box"><div class="m-hdimg"><a class="hdimg img" href="/"><img class="nofancybox" src="/img/profile.jpg" width="128" height="128"></a><h1 class="ttl"><a href="/">Frey's blog</a></h1></div><p class="m-desc">空悲眼界高，敢怨人间小。<br>越不爱人间，越觉人间好。</p><div class="m-nav"><ul><li><span class="dot">●</span><a href="/archives/">归档</a></li><li><span class="dot">●</span><a href="/categories/">分类</a></li><li><span class="dot">●</span><a href="/tags/">标签</a></li><li><span class="dot">●</span><a href="/about/">关于</a></li><li><span class="dot">●</span><a href="/atom.xml">RSS</a></li><li class="m-sch"><form class="form" id="j-formsch" action="/search" method="get"><input class="txt" type="text" id="local-search-input" name="q" value="搜索" onfocus="if(this.value=='搜索'){this.value='';}" onblur="if(this.value==''){this.value='搜索';}"></form></li></ul><div id="local-search-result"></div></div><amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-3597458182538053" data-ad-slot="7295042689" data-auto-format="rspv" data-full-width><div overflow></div></amp-ad></nav></div><div id="back2Top"><a class="fa fa-arrow-up" title="Back to top" href="#"></a></div><div class="box" id="container"><div class="l-wrapper"><div class="l-content box"><div class="l-postlist"><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/矩阵中的求导/">矩阵中的求导</a></h1><div class="p-content"><h3 id="标量对向量求导"><a href="#标量对向量求导" class="headerlink" title="标量对向量求导"></a>标量对向量求导</h3><script type="math/tex; mode=display">
y = f(x_1,\cdots,x_i,\cdots,x_n) \\
X = [x_1,\cdots,x_i,\cdots,x_n]</script><script type="math/tex; mode=display">
\frac {\partial y}{\partial X} = [\frac {\partial f}{\partial x_1},\cdots,\frac {\partial f}{\partial x_i},\cdots,\frac {\partial f}{\partial x_n}]</script></div><p class="p-readmore"><a href="/2019/矩阵中的求导/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/矩阵中的求导/">2019-10-02</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/数学/">数学</a>&nbsp;&bull;&nbsp;<a href="/categories/数学/基础知识/">基础知识</a></span><span class="p-tags"><i class="fa fa-tag"></i><a href="/tags/矩阵求导/">矩阵求导</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/交叉熵损失的反向传播/">交叉熵损失的反向传播</a></h1><div class="p-content"><p>对于一个单标签多分类问题,假设网络的输出层的输入为$Z_{in}=[z_1,\cdots,z_i,\cdots,z_n]$,输出为$\hat Y=[\hat y_1,\cdots,\hat y_i,\cdots,\hat y_n]$,真实类标签为$Y = [y_1,\cdots,y_i,\cdots,y_n]$,$n$为类别数(输出层神经元数),通常有:</p>
<script type="math/tex; mode=display">
\hat Y = Softmax(Z_{in})\label{1}\tag{1}</script><script type="math/tex; mode=display">
\hat y_i = \frac {e^{z_i}}{\sum_{j=0}^n e^{z_j}}\label{2}\tag{2}</script></div><p class="p-readmore"><a href="/2019/交叉熵损失的反向传播/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/交叉熵损失的反向传播/">2019-10-02</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/神经网络/">神经网络</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/交叉熵损失/">交叉熵损失</a><a href="/tags/反向传播/">反向传播</a><a href="/tags/Softmax/">Softmax</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/日常笔记-1/">日常笔记-1</a></h1><div class="p-content"><h3 id="pickle序列化与反序列化"><a href="#pickle序列化与反序列化" class="headerlink" title="pickle序列化与反序列化"></a>pickle序列化与反序列化</h3><pre><code class="lang-python">import pickle as plk</code></pre></div><p class="p-readmore"><a href="/2019/日常笔记-1/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/日常笔记-1/">2019-09-24</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/日常笔记/">日常笔记</a></span><span class="p-tags"><i class="fa fa-tag"></i><a href="/tags/pickle/">pickle</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/nvidia显卡驱动错误/">nvidia显卡驱动错误</a></h1><div class="p-content"><p>系统使用<code>bumblebee</code>实现双显卡(N卡和集成显卡)切换，<br>同时有N卡的开源驱动nouveau和专有显卡驱动nvidia</p>
<p>使用命令</p>
<pre><code class="lang-sh">optirun glxspheres64
# 或者optirun glxspher</code></pre></div><p class="p-readmore"><a href="/2019/nvidia显卡驱动错误/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/nvidia显卡驱动错误/">2019-09-09</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/软件使用/">软件使用</a>&nbsp;&bull;&nbsp;<a href="/categories/软件使用/Linux/">Linux</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/nvidia/">nvidia</a><a href="/tags/nouveau/">nouveau</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/基于统计的分词方法/">基于统计的分词方法</a></h1><div class="p-content"><h2 id="1-n元语言模型-n-gram"><a href="#1-n元语言模型-n-gram" class="headerlink" title="1.n元语言模型(n-gram)"></a>1.n元语言模型(n-gram)</h2><p>假设$S$表示长度为$i$，由$(w_1,w_2,\dots,w_m)$字序列组成的句子，则代表$S​$的概率为：</p></div><p class="p-readmore"><a href="/2019/基于统计的分词方法/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/基于统计的分词方法/">2019-09-08</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/自然语言处理/">自然语言处理</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/分词/">分词</a><a href="/tags/统计学/">统计学</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/神经图灵机/">神经图灵机</a></h1><div class="p-content"><h3 id="Neural-Turing-Machines-原文"><a href="#Neural-Turing-Machines-原文" class="headerlink" title="Neural Turing Machines[原文]"></a>Neural Turing Machines[<a href="https://arxiv.org/abs/1410.5401" target="_blank" rel="noopener">原文</a>]</h3><ul></ul></div><p class="p-readmore"><a href="/2019/神经图灵机/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/神经图灵机/">2019-09-07</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/论文笔记/">论文笔记</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/图灵机/">图灵机</a><a href="/tags/神经网络/">神经网络</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/运用自注意力机制检测相关语境进行多论对话/">运用自注意力机制检测相关语境进行多论对话</a></h1><div class="p-content"><h3 id="ReCoSa-Detecting-the-Relevant-Contexts-with-Self-Attention-forMulti-turn-Dialogue-Generation-原文"><a href="#ReCoSa-Detecting-the-Relevant-Contexts-with-Self-Attention-forMulti-turn-Dialogue-Generation-原文" class="headerlink" title="ReCoSa: Detecting the Relevant Contexts with Self-Attention forMulti-turn Dialogue Generation[原文]"></a>ReCoSa: Detecting the Relevant Contexts with Self-Attention forMulti-turn Dialogue Generation[<a href="https://arxiv.org/abs/1907.05339" target="_blank" rel="noopener">原文</a>]</h3><p>模型</p></div><p class="p-readmore"><a href="/2019/运用自注意力机制检测相关语境进行多论对话/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/运用自注意力机制检测相关语境进行多论对话/">2019-09-07</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/论文笔记/">论文笔记</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/多论对话/">多论对话</a><a href="/tags/Self-Attention/">Self-Attention</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/小样本学习的边缘标签图神经网络/">小样本学习的边缘标签图神经网络</a></h1><div class="p-content"><h3 id="Edge-Labeling-Graph-Neural-Network-for-Few-shot-Learning-原文"><a href="#Edge-Labeling-Graph-Neural-Network-for-Few-shot-Learning-原文" class="headerlink" title="Edge-Labeling Graph Neural Network for Few-shot Learning[原文]"></a>Edge-Labeling Graph Neural Network for Few-shot Learning[<a href="https://arxiv.org/abs/1905.01436" target="_blank" rel="noopener">原文</a>]</h3><p>小样本学习的边缘标签图神经网络</p></div><p class="p-readmore"><a href="/2019/小样本学习的边缘标签图神经网络/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/小样本学习的边缘标签图神经网络/">2019-09-06</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/论文笔记/">论文笔记</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/深度学习/">深度学习</a><a href="/tags/图网络/">图网络</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/记一次GRUB引导修复/">记一次GRUB引导修复</a></h1><div class="p-content"><p>使用Arch Linux已经2年多了，基本上已经习惯了，可前段时间英雄联盟也出了“自走棋”，想要体验一把。<br>于是就在硬盘剩余的60多个G上装了Windows 10，用了一两个月没有问题，最后再一次Windows 10更新后，蓝屏了。又手惨的点了Windows 的修复功能。等了半天，结果是修复，重启，蓝屏无限循环。而且Arch Linux的引导全都没了，感激应该是Windows的修复动了efi分区。<br>无奈只能新修复引导，各种方法尝试了好多边都是卡在了<code>GRUB _</code>一直闪这个状态，最终在官网wiki找到了办法<br><a href="https://wiki.archlinux.org/index.php/GRUB_#Default/fallback_boot_path" target="_blank" rel="noopener">缺省/后备启动路径</a><br>grub 安装时添加<code>--removable</code>参数</p></div><p class="p-readmore"><a href="/2019/记一次GRUB引导修复/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/记一次GRUB引导修复/">2019-09-03</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/软件使用/">软件使用</a>&nbsp;&bull;&nbsp;<a href="/categories/软件使用/Linux/">Linux</a></span><span class="p-tags"><i class="fa fa-tag"></i><a href="/tags/grub/">grub</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/深度学习在中文分词和词性标注中的应用/">深度学习在中文分词和词性标注中的应用</a></h1><div class="p-content"><p>得到字向量-&gt;通过窗口方法得到字与上下文有关的向量(矩阵)-&gt;通过两个线性层和一个非线性激活函数-&gt;字的标注得分(窗口方法)-&gt;一个句子的评分矩阵$f_\theta (c_{[1:n]})$ (句子中的第$i$ 个子为标签$t$ 的得分)-&gt;定义转换分数$A_{ij}$,得到tag path 得分</p></div><p class="p-readmore"><a href="/2019/深度学习在中文分词和词性标注中的应用/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/深度学习在中文分词和词性标注中的应用/">2019-08-25</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/论文笔记/">论文笔记</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/分词/">分词</a><a href="/tags/深度学习/">深度学习</a><a href="/tags/词性标注/">词性标注</a></span></div></div></div><div class="l-pager l-pager-id box" id="page-nav"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/2/">下一页&gt;</a></div><footer><p>Copyright © 2016 - 2019 <a href="/." rel="nofollow">Frey's blog</a> | <strong><a rel="nofollow" target="_blank" href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a></strong><br><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span></span> <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span></span> | Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a>Theme with<a rel="nofollow" target="_blank" href="https://github.com/litreily/snark-hexo"> snark.</a></p></footer></div></div></div><script type="text/javascript" src="/plugins/prettify/prettify.js"></script><script type="text/javascript" src="/js/search.js"></script><script type="text/javascript" src="/js/top.js"></script><script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
    search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.1" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><!--mathjax config similar to math.stackexchange--><script>window.MathJax = {
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
    }
};</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS_HTML" async></script></body></html>